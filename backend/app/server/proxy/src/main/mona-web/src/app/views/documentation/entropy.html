<div class="row">
  <div class="col-md-12">
    <h3>Spectral Entropy and Normalized Entropy in MoNA</h3>
    <h6>MoNA uses spectral and normalized entropy to measure the quality and complexity of spectra in the database</h6>
    <br/><br/><br/>

    <h4>Criteria for Spectrum Quality</h4>
    <hr>
    <p>
      <span class="text-success"><b>CLEAN</b></span> = (Normalized entropy)<sup>4</sup> &le; 0.8 AND spectral entropy &le; 3.0<br/>
      <span class="text-danger"><b>NOISY</b></span> = (Normalized entropy)<sup>4</sup> &gt; 0.8 AND spectral entropy &gt; 3.0<br/>
    </p>

    <p class="ml-3">
      <b>Note:</b> GC-MS Spectra has an exception and is evaluated as clean
      regardless of entropy levels.
    </p>

    <br/> <br/>
    <div>
      <h4>What is Spectral Entropy?</h4>
    <hr>
    <p>
      Spectral entropy measures the total information content of an MS/MS spectrum.
      Spectral entropy is much more robust and refined compared to the commonly used "peak number" measurement. See Figure 1.
      <br/> <br/>
    </p>
    <div class="text-center">
      <img src="../../../assets/figure_1.jpg"
               alt="Figure 1: Spectra with the same number of peaks but different spectral entropy"
               width="600px">
      <p class="center">
        <br/>
        <b>Figure 1 -</b> Spectra with the same number of peaks but different spectral entropy
      </p>
    </div>

    <br/> <br/> <br/> <br/> <br/>
    <h4>How to Calculate Spectral Entropy</h4>
  <hr>
  <p>
    The spectral entropy is similar to the <em>Shannon entropy</em> in the theory of information.
    The spectral entropy can be calculated using the formula in Figure 2.
    Spectral entropy can be seen as the intensity weighted spectral entropy.
  </p>
  <div class="text-center">
    <img src="../../../assets/figure_2.jpg" alt="Figure 2. The formula of calculating spectral entropy"
             width="450px"
             class="center">

    <p class="center">
      <br/>
      <b>Figure 2 -</b> The formula for calculating spectral entropy
    </p>
  </div>

    <br/> <br/> <br/> <br/> <br/>
    <h4>Spectral Entropy Across Different Databases</h4>
    <hr>
    <p>
      Most small molecule spectra have a spectral entropy between 0 and 5. See Figure 3.
    </p>
    <div class="text-center">
      <img src="../../../assets/figure_3.jpg"
               alt="Figure 3: Distribution of spectral entropies in the NIST20, MassBank.us and GNPS databases."
               width="600px" class="center">
      <p class="center">
        <br/>
        <b>Figure 3 -</b> Distribution of spectral entropies in the NIST20, MassBank.us and GNPS databases.
      </p>
    </div>

    <br/><br/><br/><br/><br/>
    <h4>How to Calculate Normalized Entropy</h4>
    <hr>
    <p>
      The spectral entropy ranges from 0 to <code class="code-text">ln(peak number)</code>.
      The spectral entropy can be normalized to <code class="code-text">[0,1]</code> by dividing the spectral entropy by <code class="code-text">ln(peak number)</code>.
      Therefore, normalized entropy is calculated as follows:
      <br/> <br/>
    </p>
    <div class="text-center">
      <img src="../../../assets/figure_4.jpg" alt="Figure 4. The formula of calculating normalized entropy."
               width="450px" class="center">
      <p class="center">
        <br/>
        <b>Figure 4 -</b> The formula of calculating normalized entropy.
      </p>
    </div>

    <br/><br/><br/><br/><br/>
    <h4>Distribution of Normalized Entropy</h4>
    <hr>
    <p>
      We injected 216 metabolites into 13 different concentrations, and collected in 3 different collision energies, which
      resulted in 9,695 spectra. We then divided those spectra into two groups: high quality and low quality. The normalized
      entropy of each group is shown in Figure 5.
    </p>
    <div class="text-center">
      <img src="../../../assets/figure_5.jpg" alt="Figure 5. Distribution of normalized entropies in spectra with different quality."
               width="450px" class="center">
      <p class="center">
        <br/>
        <b>Figure 5 -</b> Distribution of normalized entropy in spectra with different quality
      </p>
    </div>

      <br/>
      <hr>
      <h4>Reference</h4>
      <p>
        Yuanyue Li, Tobias Kind, Jacob Folz, Arpana Vaniya, Sajjan Singh Mehta & Oliver Fiehn<br/>

        <a href="https://doi.org/10.1038/s41592-021-01331-z">Spectral entropy outperforms MS/MS dot
          product similarity for small-molecule compound identification</a><br/>

        Nat Methods 18, 1524â€“1531 (2021)
      </p>
    </div>
  </div>
</div>
